---
phase: 07-observability
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - worker/src/health.py
  - worker/src/main.py
  - worker/src/config.py
autonomous: true

must_haves:
  truths:
    - "Health check endpoint returns 200 OK when worker is healthy"
    - "Health check returns 503 when last scrape failed"
    - "Health endpoint exposes last_scrape_time and status"
    - "External monitoring can poll the health endpoint"
  artifacts:
    - path: "worker/src/health.py"
      provides: "HTTP health check server"
      contains: "class HealthServer"
    - path: "worker/src/main.py"
      provides: "Health server started with worker"
      contains: "HealthServer"
  key_links:
    - from: "worker/src/main.py"
      to: "worker/src/health.py"
      via: "import and start"
      pattern: "HealthServer"
    - from: "worker/src/health.py"
      to: "worker state"
      via: "last_scrape tracking"
      pattern: "last_scrape_time"
---

<objective>
Add HTTP health check endpoint to the Python worker for external monitoring and alerting.

Purpose: Enable uptime monitoring services (UptimeRobot, Railway's built-in health checks, or Sentry Crons) to detect worker failures and trigger alerts when the worker is unhealthy or stops processing.

Output: Health check server running alongside the worker, exposing /health endpoint with status and last scrape timestamp.
</objective>

<execution_context>
@/home/qualia/.claude/get-shit-done/workflows/execute-plan.md
@/home/qualia/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@worker/src/main.py
@worker/src/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create health check HTTP server</name>
  <files>
    worker/src/health.py
    worker/src/config.py
  </files>
  <action>
    1. Add health_port setting to worker/src/config.py:
       ```python
       health_port: int = 8080
       ```

    2. Create worker/src/health.py:
       ```python
       import json
       import threading
       from http.server import HTTPServer, BaseHTTPRequestHandler
       from datetime import datetime, timezone
       from typing import Optional
       import structlog

       log = structlog.get_logger()

       # Global state for health tracking
       _health_state = {
           "status": "starting",
           "last_scrape_time": None,
           "last_scrape_success": None,
           "scrape_count": 0,
           "error_count": 0,
       }


       def update_health(success: bool, scrape_count: int = 0):
           """Update health state after a scrape cycle."""
           _health_state["last_scrape_time"] = datetime.now(timezone.utc).isoformat()
           _health_state["last_scrape_success"] = success
           _health_state["scrape_count"] += scrape_count
           if success:
               _health_state["status"] = "healthy"
           else:
               _health_state["status"] = "degraded"
               _health_state["error_count"] += 1


       def set_status(status: str):
           """Set worker status (starting, healthy, degraded, stopped)."""
           _health_state["status"] = status


       class HealthHandler(BaseHTTPRequestHandler):
           """HTTP handler for health check requests."""

           def log_message(self, format, *args):
               # Suppress default HTTP logging, use structlog instead
               pass

           def do_GET(self):
               if self.path == "/health":
                   self._handle_health()
               elif self.path == "/":
                   self._handle_root()
               else:
                   self.send_error(404)

           def _handle_root(self):
               self.send_response(200)
               self.send_header("Content-Type", "text/plain")
               self.end_headers()
               self.wfile.write(b"Axidex Worker")

           def _handle_health(self):
               status = _health_state["status"]
               http_code = 200 if status in ("healthy", "starting") else 503

               response = {
                   "status": status,
                   "last_scrape_time": _health_state["last_scrape_time"],
                   "last_scrape_success": _health_state["last_scrape_success"],
                   "scrape_count": _health_state["scrape_count"],
                   "error_count": _health_state["error_count"],
                   "timestamp": datetime.now(timezone.utc).isoformat(),
               }

               self.send_response(http_code)
               self.send_header("Content-Type", "application/json")
               self.end_headers()
               self.wfile.write(json.dumps(response).encode())


       class HealthServer:
           """Threaded HTTP server for health checks."""

           def __init__(self, port: int = 8080):
               self.port = port
               self.server: Optional[HTTPServer] = None
               self.thread: Optional[threading.Thread] = None

           def start(self):
               """Start health server in background thread."""
               self.server = HTTPServer(("0.0.0.0", self.port), HealthHandler)
               self.thread = threading.Thread(target=self.server.serve_forever, daemon=True)
               self.thread.start()
               log.info("health_server_started", port=self.port)

           def stop(self):
               """Stop health server."""
               if self.server:
                   self.server.shutdown()
                   log.info("health_server_stopped")
       ```

    IMPORTANT: The health server runs in a daemon thread so it doesn't block the main scheduler loop. It exposes:
    - GET / -> "Axidex Worker" (basic liveness)
    - GET /health -> JSON with detailed status (readiness)
  </action>
  <verify>
    - worker/src/health.py exists
    - worker/src/config.py includes health_port setting
    - grep "HealthServer" worker/src/health.py returns matches
  </verify>
  <done>
    Health check HTTP server module created with /health endpoint returning JSON status, last scrape time, and error counts.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate health server with main worker loop</name>
  <files>
    worker/src/main.py
  </files>
  <action>
    1. Add imports at top of worker/src/main.py:
       ```python
       from .health import HealthServer, update_health, set_status
       ```

    2. Update run_scrapers() to track health:
       - At the END of run_scrapers(), after the scraper loop completes:
         ```python
         # Update health status
         all_success = all(count > 0 or count == 0 for count in signals_by_source.values())
         # Consider it a failure if ALL scrapers returned 0 (possible network/auth issue)
         had_failures = any(signals_by_source.get(s.name, 0) == 0 and s.name in [scraper.name for scraper in scrapers] for s in scrapers)

         # Simpler check: success if we got ANY signals, or if individual scrapers didn't throw
         success = total_signals > 0 or not had_failures
         update_health(success=success, scrape_count=total_signals)
         ```

       - Actually, simplify to: after the for loop ends, add:
         ```python
         # Update health: success if no exceptions were raised (errors logged but continued)
         update_health(success=True, scrape_count=total_signals)
         ```
         And in the except block, the error is already logged. We track it separately.

    3. Update main() function:
       - After settings = get_settings() but BEFORE running the first job:
         ```python
         # Start health check server
         health_server = HealthServer(port=settings.health_port)
         health_server.start()
         set_status("healthy")
         ```

       - The health server runs in daemon thread, so it auto-stops when main process exits.

    4. For robust error tracking, update the exception handler in run_scrapers():
       - Add to the except block: Track that a scraper failed so health can reflect it
       - Actually, the current structure already logs errors. Just add update_health at the end:

       After the for scraper loop, ADD:
       ```python
       # Determine if any scraper completely failed (raised exception)
       # The exception is caught per-scraper, so if we reach here, the cycle completed
       update_health(success=True, scrape_count=total_signals)
       ```

    5. If run_scrapers() itself throws (unlikely but possible), wrap the call in job():
       ```python
       def job():
           """Wrapper to run async scrapers from sync scheduler."""
           try:
               asyncio.run(run_scrapers())
           except Exception as e:
               log.error("scrape_cycle_failed", error=str(e))
               update_health(success=False, scrape_count=0)
               # Re-raise to ensure Sentry captures it (if configured in plan 07-01)
               raise
       ```

    IMPORTANT: Railway expects port 8080 by default for health checks. The health_port config allows override via HEALTH_PORT env var if needed.
  </action>
  <verify>
    - grep "HealthServer" worker/src/main.py finds import and instantiation
    - grep "update_health" worker/src/main.py finds at least 2 calls
    - grep "health_server.start" worker/src/main.py finds the start call
  </verify>
  <done>
    Health server starts with worker, tracks scrape cycle success/failure, and exposes /health endpoint for external monitoring.
  </done>
</task>

<task type="auto">
  <name>Task 3: Document alerting setup for Railway/UptimeRobot</name>
  <files>
    .planning/phases/07-observability/ALERTING-SETUP.md
  </files>
  <action>
    Create a brief markdown file documenting how to configure alerting:

    ```markdown
    # Axidex Worker Alerting Setup

    The worker exposes a health endpoint at `GET /health` on port 8080 (configurable via HEALTH_PORT).

    ## Health Response

    ```json
    {
      "status": "healthy",
      "last_scrape_time": "2026-01-31T12:00:00Z",
      "last_scrape_success": true,
      "scrape_count": 42,
      "error_count": 0,
      "timestamp": "2026-01-31T12:05:00Z"
    }
    ```

    Status values: `starting`, `healthy`, `degraded`, `stopped`
    - 200 OK: `healthy` or `starting`
    - 503 Service Unavailable: `degraded` or `stopped`

    ## Railway Health Check

    Railway automatically detects the health endpoint. To configure explicitly:

    1. Go to Railway Dashboard -> axidex-worker -> Settings
    2. Under "Health Check", set:
       - Path: `/health`
       - Port: `8080`
       - Interval: `60` (seconds)

    Railway will restart the service if health checks fail.

    ## UptimeRobot Setup (External Monitoring)

    1. Create account at uptimerobot.com (free tier: 50 monitors)
    2. Add New Monitor:
       - Type: HTTP(s)
       - URL: `https://axidex-worker-production.up.railway.app/health`
       - Interval: 5 minutes
    3. Configure Alert Contacts (email, Slack, etc.)

    ## Sentry Crons (Alternative)

    Sentry Crons can monitor scheduled jobs. Add to worker after a scrape cycle:

    ```python
    import sentry_sdk
    from sentry_sdk.crons import monitor

    @monitor(monitor_slug='axidex-worker-scrape')
    async def run_scrapers():
        # ... existing code
    ```

    Configure in Sentry Dashboard -> Crons to alert on missed check-ins.
    ```

    This is documentation only - actual alerting config is a user_setup step done manually.
  </action>
  <verify>
    - File .planning/phases/07-observability/ALERTING-SETUP.md exists
  </verify>
  <done>
    Alerting documentation created with Railway health check config, UptimeRobot setup, and Sentry Crons option.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. worker/src/health.py exists with HealthServer class
2. worker/src/main.py imports and starts HealthServer
3. Health state is updated after each scrape cycle
4. ALERTING-SETUP.md documents external monitoring options
5. Worker can be tested locally: `python -m src.main` then `curl localhost:8080/health`
</verification>

<success_criteria>
- Health check endpoint returns 200 with JSON status when healthy
- Health check returns 503 when worker enters degraded state
- Health server runs in background thread without blocking scheduler
- Documentation exists for Railway health check and external alerting
- Port is configurable via HEALTH_PORT environment variable
</success_criteria>

<output>
After completion, create `.planning/phases/07-observability/07-02-SUMMARY.md`
</output>
